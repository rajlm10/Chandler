{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf7dSA5xoaRd"
      },
      "source": [
        "# **Sarcasm Detector** - *Final Deployed Version*\n",
        "\n",
        "Welcome to the notebook which depicts the training of a sarcasm detection model based on the techniques listed in the popular paper titled **Attention is all you need** (Vaswani et al). [Here](https://arxiv.org/abs/1706.03762) is the link to the original paper. Some insights were also derived from the paper titled **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding** (Google AI Language). This paper can be found [here](https://arxiv.org/pdf/1810.04805.pdf)\n",
        "\n",
        "*The model in this final version uses self-attention (Paralleized through Multi-Headed Attention) , subword tokenization , and positional encodings (in combination with word embeddings). These techniques have been used to create an Encoder which consists of 6 encoder layers , each layer consisting of a fully connected feed-forward network of size 512. 8 attention heads have been used. Each section has been comprehensively described in the readme file.*\n",
        "\n",
        "In the previous notebook we trained three similar models (revolving around the Encoder architecture) using Encoders with a CNN layer and Encoders with a LSTM layer. However on some experimentation I found this version of the model to work best for my task. Even more impressively the model generalizes well and only consumes **28 MB of space**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bo0Nk0_juZ1",
        "outputId": "2e891548-80d2-4a8b-92eb-509586b8182b"
      },
      "source": [
        "print(tf.__version__)\n",
        "print(nltk.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "3.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCS6oQYSoci1",
        "outputId": "54e109dd-8aaf-41e9-d9f1-f66b43f4dcbe"
      },
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import time\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xACPGDN0bdwD"
      },
      "source": [
        "df1=pd.read_json(\"/content/Sarcasm_Headlines_Dataset_v2.json\",lines=True) #Reading the dataframe\n",
        "df1=df1[['headline','is_sarcastic']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYUBAbzEbgzm",
        "outputId": "f971d355-1fc8-45c5-ffc0-e29d5b067f99"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28619 entries, 0 to 28618\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   headline      28619 non-null  object\n",
            " 1   is_sarcastic  28619 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 447.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8TzZYdLbhSw"
      },
      "source": [
        "#Undersampling 10 percent of the sarcastic comments. This improved the f1-score after conducting a few experiments.\n",
        "df=df1.drop(df1[df1['is_sarcastic']==1].sample(frac=0.10).index) \n",
        "df=df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ydH1M941bi7c",
        "outputId": "cc86ce9e-5187-4a97-fdef-31a49f9c1946"
      },
      "source": [
        "#Observing the dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           headline  is_sarcastic\n",
              "0      0  thirtysomething scientists unveil doomsday clo...             1\n",
              "1      1  dem rep. totally nails why congress is falling...             0\n",
              "2      2  eat your veggies: 9 deliciously different recipes             0\n",
              "3      3  inclement weather prevents liar from getting t...             1\n",
              "4      4  mother comes pretty close to using word 'strea...             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "_ACsXzI8bq9U",
        "outputId": "51994a4e-ca9e-4ae4-d65c-0a5c88ef758d"
      },
      "source": [
        "#Visualising the target variable after undersampling\n",
        "sns.countplot(data=df,x=df.is_sarcastic);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ElxBKLL_bs_L",
        "outputId": "65a56eea-18c8-48aa-be12-5530da2f881f"
      },
      "source": [
        "#Seeing some sarcastic comments\n",
        "pd.options.display.max_colwidth = 200\n",
        "pd.DataFrame(df[df['is_sarcastic']==1]['headline']).head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thirtysomething scientists unveil doomsday clock of hair loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>inclement weather prevents liar from getting to work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mother comes pretty close to using word 'streaming' correctly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>richard branson's global-warming donation nearly as much as cost of failed balloon trips</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>shadow government getting too large to meet in marriott conference room b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ford develops new suv that runs purely on gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>area boy enters jumping-and-touching-tops-of-doorways phase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>area man does most of his traveling by gurney</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>guard in video game under strict orders to repeatedly pace same stretch of hallway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>secret service agent not so secret about being david alan grier fan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                    headline\n",
              "0                              thirtysomething scientists unveil doomsday clock of hair loss\n",
              "3                                       inclement weather prevents liar from getting to work\n",
              "4                              mother comes pretty close to using word 'streaming' correctly\n",
              "7   richard branson's global-warming donation nearly as much as cost of failed balloon trips\n",
              "8                  shadow government getting too large to meet in marriott conference room b\n",
              "14                                        ford develops new suv that runs purely on gasoline\n",
              "16                               area boy enters jumping-and-touching-tops-of-doorways phase\n",
              "17                                             area man does most of his traveling by gurney\n",
              "21        guard in video game under strict orders to repeatedly pace same stretch of hallway\n",
              "25                       secret service agent not so secret about being david alan grier fan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOla81VqbtZy"
      },
      "source": [
        "#Utility functions to help preprocess text and map conntractions\n",
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s$\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "stopwords_english = set(stopwords.words('english'))-set(['No','no','not','Not'])\n",
        "def preprocess(text,stopwords=stopwords_english):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    # remove hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    #Decontract texts\n",
        "    text=decontract(text)\n",
        "    # tokenize texts\n",
        "\n",
        "\n",
        "    texts_clean = []\n",
        "    for word in text.split():\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in set(string.punctuation)-set(['!','?','.','@',':'])):  # remove punctuation\n",
        "            #Lemmatize word \n",
        "            lem_word = lemmatizer.lemmatize(word,\"v\")  # Lemmatizing word\n",
        "            texts_clean.append(lem_word)\n",
        "\n",
        "    return \" \".join(texts_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGbTK_-DbvRo"
      },
      "source": [
        "#Transform the inputs and also split the data into training and test sets.\n",
        "#I have used a split of 80-20 to make sure our model learns better since it is deep.\n",
        "inputs=list(df['headline'].apply(lambda x: preprocess(x)))\n",
        "labels=list(df['is_sarcastic'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8dgwbn9Fbw73",
        "outputId": "37015413-b6f0-4967-c649-d5585976bd48"
      },
      "source": [
        "#Making sure our split is balanced\n",
        "sns.countplot(x=y_train);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YTVCgMPbzrH"
      },
      "source": [
        "#Tokenizing using subwords as opposed to characters or entire words. This helps improve performance and was used while training BERT ,\n",
        "#The maxlen of 50 has been experimentally chosen and is shorter than a few of the longest training inputs. This was done \n",
        "# as most inputs are within this length and we can train faster. \n",
        "def subword_tokenize(train_corpus, vocab_size=2**14, max_length=50,tokenizer=None):\n",
        "  # Create the vocabulary using Subword tokenization\n",
        "  if(tokenizer==None):\n",
        "    tokenizer_corpus = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_corpus, target_vocab_size=2**14)\n",
        "  else:\n",
        "    tokenizer_corpus=tokenizer\n",
        "  # Get the final vocab size\n",
        "  vocab_size = tokenizer_corpus.vocab_size \n",
        "  \n",
        "  # Tokenize the corpus\n",
        "  sentences = [tokenizer_corpus.encode(sentence) for sentence in train_corpus]\n",
        "\n",
        "  #Pad the sentences with 0s upto a length of 50\n",
        "  sentences = tf.keras.preprocessing.sequence.pad_sequences(sentences,value=0,padding='post',maxlen=50)\n",
        "  \n",
        "  return sentences, tokenizer_corpus, vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXZCmxZWb0KF"
      },
      "source": [
        "tokenized_inputs,tokenizer,vocab_size=subword_tokenize(train_corpus=X_train)\n",
        "tokenized_test_inputs,_,vocab_size2=subword_tokenize(X_test,tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYRQBxv8bULp"
      },
      "source": [
        "# import pickle\n",
        "# filename = 'tokenizer.sav'\n",
        "# pickle.dump(tokenizer, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvNHlDtgb1xq"
      },
      "source": [
        "# Define a dataset \n",
        "# A batch size of 128 has been chosen for the task\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tokenized_inputs, y_train))\n",
        "dataset = dataset.shuffle(len(tokenized_inputs), reshuffle_each_iteration=True).batch(128, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPramCOYb3Ks"
      },
      "source": [
        "# Implemented based on the Attention is all you need paper.\n",
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "    # Calculating  QK.T\n",
        "    product = tf.matmul(queries, keys, transpose_b=True)\n",
        "    # Get the scale factor\n",
        "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "    # Scale the dot product for improved training speed and stability \n",
        "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "    # Apply the mask\n",
        "    if mask is not None:\n",
        "        scaled_product += (mask * -1e9)\n",
        "    # dot product of QK.T with Values \n",
        "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "    \n",
        "    return attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1Mab3Sb4vf"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "    \n",
        "    def __init__(self, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        assert self.d_model % self.n_heads == 0\n",
        "        # Calculate the dimension of every head or projection\n",
        "        self.d_head = self.d_model // self.n_heads\n",
        "        # Set the weight matrices for Q, K and V\n",
        "        self.query_weights = layers.Dense(units=self.d_model)\n",
        "        self.key_weights = layers.Dense(units=self.d_model)\n",
        "        self.value_weights = layers.Dense(units=self.d_model)\n",
        "        # Set the weight matrix for the output of the multi-head attention W0\n",
        "        self.final_weights = layers.Dense(units=self.d_model)\n",
        "        \n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
        "        # Set the dimension of the projections\n",
        "        shape = (batch_size,\n",
        "                 -1,\n",
        "                 self.n_heads,\n",
        "                 self.d_head)\n",
        "        # Split the input vectors\n",
        "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
        "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, n_heads, seq_length, d_proj)\n",
        "    \n",
        "    def call(self, queries, keys, values, mask):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.shape(queries)[0]\n",
        "        # Set the Query, Key and Value matrices\n",
        "        queries = self.query_weights(queries)\n",
        "        keys = self.key_weights(keys)\n",
        "        values = self.value_weights(values)\n",
        "        # Split Q, K y V between the heads or projections\n",
        "        queries = self.split_proj(queries, batch_size)\n",
        "        keys = self.split_proj(keys, batch_size)\n",
        "        values = self.split_proj(values, batch_size)\n",
        "        # Apply the scaled dot product\n",
        "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "        # Get the attention scores\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        # Concat the h heads or projections\n",
        "        concat_attention = tf.reshape(attention,\n",
        "                                      shape=(batch_size, -1, self.d_model))\n",
        "        # Apply W0 to get the output of the multi-head attention\n",
        "        outputs = self.final_weights(concat_attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8INtLB-b6MI"
      },
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model): # pos: (seq_length, 1) i: (1, d_model)\n",
        "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
        "        return pos * angles # (seq_length, d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # input shape batch_size, seq_length, d_model\n",
        "        seq_length = inputs.shape.as_list()[-2]\n",
        "        d_model = inputs.shape.as_list()[-1]\n",
        "        # Calculate the angles given the input\n",
        "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
        "                                 np.arange(d_model)[np.newaxis, :],\n",
        "                                 d_model)\n",
        "        # Calculate the positional encodings\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        # Expand the encodings with a new dimension\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "        \n",
        "        return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8zGEvsrb7t-"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, FFN_units, n_heads, dropout_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        # Hidden units of the feed forward component\n",
        "        self.FFN_units = FFN_units\n",
        "        # Set the number of projectios or heads\n",
        "        self.n_heads = n_heads\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        # Build the multihead layer\n",
        "        self.multi_head_attention = MultiHeadAttention(self.n_heads)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        # Layer Normalization\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        # Fully connected feed forward layer\n",
        "        self.ffn1_relu = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.ffn2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        # Layer normalization\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self, inputs, mask, training):\n",
        "        # Forward pass of the multi-head attention\n",
        "        attention = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        # Call to the residual connection and layer normalization\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        # Call to the FC layer\n",
        "        outputs = self.ffn1_relu(attention)\n",
        "        outputs = self.ffn2(outputs)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        # Call to residual connection and the layer normalization\n",
        "        outputs = self.norm_2(outputs + attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8wyDTgKb9R5"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 FFN_units,\n",
        "                 n_heads,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        # The embedding layer\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        # Positional encoding layer\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        # Stack of n layers of multi-head attention and FC\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        n_heads,\n",
        "                                        dropout_rate) \n",
        "                           for _ in range(n_layers)]\n",
        "        self.final_layer = layers.Dense(units=2, name=\"final_layer\")\n",
        "    \n",
        "    def call(self, inputs, mask, training):\n",
        "        # Get the embedding vectors\n",
        "        outputs = self.embedding(inputs)\n",
        "        # Scale the embeddings by sqrt of d_model\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        # Positional encodding\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        # Call the stacked layers\n",
        "        for i in range(self.n_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "        #print(outputs.shape)\n",
        "\n",
        "        logits=tf.math.reduce_mean(outputs,1)\n",
        "\n",
        "\n",
        "        logits=self.final_layer(logits)\n",
        "\n",
        "        return logits "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7zJ69xydBdh"
      },
      "source": [
        "def create_padding_mask(seq): #seq: (batch_size, seq_length)\n",
        "# Create the mask for padding\n",
        "  mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKn-8H15dMn_"
      },
      "source": [
        "import pickle\n",
        "tokenizer=pickle.load(open('/content/tokenizer.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_DhXOMdDCB"
      },
      "source": [
        "loaded_model = pickle.load(open('/content/finalized_model (1).sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb0K1I6eapmV",
        "outputId": "c0f16109-8101-4404-d7a2-ee8f060470fe"
      },
      "source": [
        "example=\"Today is such a beautiful day , the weather is perfect to sit inside .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today is such a beautiful day , the weather is perfect to sit inside .\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzBqLLO8a9dv",
        "outputId": "c10f7dab-966b-4958-d5cb-1f13e0045541"
      },
      "source": [
        "example=\"Today is such a beautiful day , the weather is perfect for football .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today is such a beautiful day , the weather is perfect for football .\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3AnZWbHd1Yj",
        "outputId": "15ca0540-0b14-490f-f487-4df6041487e0"
      },
      "source": [
        "example=\"Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmA-SodWb_Nq"
      },
      "source": [
        "def create_padding_mask(seq): #seq: (batch_size, seq_length)\n",
        "# Create the mask for padding\n",
        "  mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def loss_function(target, pred): #Notice from_logits=True\n",
        "  return tf.keras.losses.BinaryCrossentropy(from_logits=True)(target,pred)\n",
        "\n",
        "#Use a custom scheduler as per the paper with 4000 warmup steps\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        \n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "        \n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEfNo7ScA1M"
      },
      "source": [
        "def main_train(dataset, encoder, n_epochs, print_every=50):\n",
        "  ''' Train the Encoder model for n epochs using the data generator dataset'''\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  # In every epoch\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Starting epoch {}\".format(epoch+1))\n",
        "    start = time.time()\n",
        "    # Reset the losss and accuracy calculations\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    # Get a batch of inputs and targets\n",
        "    for (batch, (inputs, targets)) in enumerate(dataset):\n",
        "\n",
        "        #Since we are using the binary cross entropy loss\n",
        "        targets = pd.get_dummies(targets).astype('float').values\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Call the transformer and get the predicted output\n",
        "            predictions = encoder(inputs, create_padding_mask(inputs), True)\n",
        "            # Calculate the loss\n",
        "            loss = loss_function(targets, predictions)\n",
        "        # Update the weights and optimizer\n",
        "        gradients = tape.gradient(loss, encoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, encoder.trainable_variables))\n",
        "        # Save and store the metrics\n",
        "        train_loss(loss)\n",
        "       \n",
        "        train_accuracy(targets, predictions)\n",
        "        \n",
        "        if batch % print_every == 0:\n",
        "            losses.append(train_loss.result())\n",
        "            accuracies.append(train_accuracy.result())\n",
        "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "                epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "            \n",
        "\n",
        "\n",
        "  return losses, accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utdLvwh03f7W"
      },
      "source": [
        "ENCODER_LAYERS=6\n",
        "FFN_UNITS=512\n",
        "ATTN_HEADS=8\n",
        "DROPOUT_RATE=0.1\n",
        "EMBEDDING_DIM=256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn8htCjYcDhK"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Create the Encoder model\n",
        "encoder = Encoder(ENCODER_LAYERS,FFN_UNITS,ATTN_HEADS,DROPOUT_RATE,vocab_size,EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "# Define a metric to store the mean loss of every epoch\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "# Define a matric to save the accuracy in every epoch\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
        "# Create the scheduler for learning rate decay\n",
        "leaning_rate = CustomSchedule(256)\n",
        "# Create the Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPWk_ITscFDn",
        "outputId": "92295712-6e6b-4b98-e98a-e6d7992b26d5"
      },
      "source": [
        "losses, accuracies = main_train(dataset, encoder, 5). #Training beyond 5 epochs causes overfitting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "Epoch 1 Batch 0 Loss 0.9332 Accuracy 0.4180\n",
            "Epoch 1 Batch 50 Loss 0.7477 Accuracy 0.5058\n",
            "Epoch 1 Batch 100 Loss 0.7185 Accuracy 0.5117\n",
            "Epoch 1 Batch 150 Loss 0.7015 Accuracy 0.5238\n",
            "Starting epoch 2\n",
            "Epoch 2 Batch 0 Loss 0.6059 Accuracy 0.6367\n",
            "Epoch 2 Batch 50 Loss 0.6105 Accuracy 0.6477\n",
            "Epoch 2 Batch 100 Loss 0.5931 Accuracy 0.6643\n",
            "Epoch 2 Batch 150 Loss 0.5717 Accuracy 0.6828\n",
            "Starting epoch 3\n",
            "Epoch 3 Batch 0 Loss 0.4384 Accuracy 0.7734\n",
            "Epoch 3 Batch 50 Loss 0.4335 Accuracy 0.7903\n",
            "Epoch 3 Batch 100 Loss 0.4288 Accuracy 0.7919\n",
            "Epoch 3 Batch 150 Loss 0.4286 Accuracy 0.7926\n",
            "Starting epoch 4\n",
            "Epoch 4 Batch 0 Loss 0.3200 Accuracy 0.8672\n",
            "Epoch 4 Batch 50 Loss 0.3021 Accuracy 0.8681\n",
            "Epoch 4 Batch 100 Loss 0.3116 Accuracy 0.8627\n",
            "Epoch 4 Batch 150 Loss 0.3107 Accuracy 0.8624\n",
            "Starting epoch 5\n",
            "Epoch 5 Batch 0 Loss 0.2176 Accuracy 0.9102\n",
            "Epoch 5 Batch 50 Loss 0.2106 Accuracy 0.9112\n",
            "Epoch 5 Batch 100 Loss 0.2164 Accuracy 0.9077\n",
            "Epoch 5 Batch 150 Loss 0.2304 Accuracy 0.9018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwMqCAqUeEkB"
      },
      "source": [
        "def predict(encoder,tokenized_sentences):\n",
        "  logits=encoder(tokenized_sentences,create_padding_mask(tokenized_sentences),False)\n",
        "  predictions=np.argmax(tf.keras.layers.Softmax()(logits),axis=1)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zabjf2dp5_Bf",
        "outputId": "23a0b7f7-6da9-46f8-cf7c-a5dadd348633"
      },
      "source": [
        "test_accuracy=sum((predict(encoder,tokenized_test_inputs)==y_test))\n",
        "test_accuracy/=len(y_test)\n",
        "print(test_accuracy)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predict(encoder,tokenized_test_inputs),y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8231841526045488\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.84      3150\n",
            "           1       0.77      0.83      0.80      2302\n",
            "\n",
            "    accuracy                           0.82      5452\n",
            "   macro avg       0.82      0.82      0.82      5452\n",
            "weighted avg       0.83      0.82      0.82      5452\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8fJMnmcMeF"
      },
      "source": [
        "examples=['Woman wins award for safe driving','I work forty hours a week for me to be this poor.','I would kill for a Nobel Peace Prize.','Depression is merely anger without enthusiasm.','Two wrongs dont make a right take your parents as an example .','If I wanted to kill myself Id climb your ego and jump to your IQ.','Always remember that you are absolutely unique just like everyone else .','Congratulations, If you press the elevator button three times it goes into hurry mode  really...','Hello my name is Raj and I study computer science!','Please get me some fruits from the store .','Want to hang out today ?','Presidency is probably the toughest job around','We should go out and play football','Discounted items end up being the most expensive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIA2xwGB6KTY",
        "outputId": "6035ea1c-f4b0-40ba-a628-d747a88ac73c"
      },
      "source": [
        "#example='Woman wins award for safe driving'\n",
        "for example in examples:\n",
        "  sentence=tokenizer.encode(preprocess(example))\n",
        "  sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "  print(example)\n",
        "  print(predict(encoder,sentence))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woman wins award for safe driving\n",
            "[0]\n",
            "I work forty hours a week for me to be this poor.\n",
            "[1]\n",
            "I would kill for a Nobel Peace Prize.\n",
            "[1]\n",
            "Depression is merely anger without enthusiasm.\n",
            "[1]\n",
            "Two wrongs dont make a right take your parents as an example .\n",
            "[0]\n",
            "If I wanted to kill myself Id climb your ego and jump to your IQ.\n",
            "[0]\n",
            "Always remember that you are absolutely unique just like everyone else .\n",
            "[0]\n",
            "Congratulations, If you press the elevator button three times it goes into hurry mode  really...\n",
            "[1]\n",
            "Hello my name is Raj and I study computer science!\n",
            "[0]\n",
            "Please get me some fruits from the store .\n",
            "[1]\n",
            "Want to hang out today ?\n",
            "[0]\n",
            "Presidency is probably the toughest job around\n",
            "[1]\n",
            "We should go out and play football\n",
            "[0]\n",
            "Discounted items end up being the most expensive\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3ncyBVIcNCO",
        "outputId": "15b69efe-71ea-4be4-f5f8-b48f5cb7b088"
      },
      "source": [
        "example=\"Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(encoder,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z04ZhdkycPdt",
        "outputId": "c11116f3-7ae4-46bd-9e84-47fb105b5a54"
      },
      "source": [
        "example=\"Today is such a beautiful day , the weather is perfect to sit inside .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(encoder,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today is such a beautiful day , the weather is perfect to sit inside .\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7MMQTgqcgXD",
        "outputId": "f3109595-48de-453e-cd5e-055296f88d11"
      },
      "source": [
        "#Predict probability for preprocessed tokenized sentences \n",
        "def predict_proba2(encoder,examples):\n",
        "\n",
        "    logits=encoder(examples,create_padding_mask(examples),False)\n",
        "    return layers.Softmax()(logits).numpy()\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(roc_auc_score(y_test, predict_proba2(encoder,tokenized_test_inputs)[:, 1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9062273714207801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "GKXm2zeL8V2b",
        "outputId": "71dde9ad-6d56-46c1-cbad-915b9172c52c"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for our model\n",
        "fpr, tpr, thresh = roc_curve(y_test, predict_proba2(loaded_model,tokenized_test_inputs)[:, 1], pos_label=1)\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.lineplot(x=fpr,y=tpr,);\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\");\n",
        "plt.ylabel(\"Sensitivity (TPR)\");\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYbhHqgZfcR1"
      },
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(encoder, open(filename, 'wb'))\n",
        "loaded_model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pSMwOZBen6Y",
        "outputId": "d0ad1769-9504-43a1-f6ec-10626cedc91d"
      },
      "source": [
        "print(roc_auc_score(y_test, predict_proba2(loaded_model,tokenized_test_inputs)[:, 1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9062273714207801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy9GIHWu665T",
        "outputId": "43338f58-61da-4f7c-b8b3-2d919cfe1cc5"
      },
      "source": [
        "example=\"I am so happy to be working with you guys.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am so happy to be working with you guys.\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VtwgJ_AfXNP",
        "outputId": "3f3a0dfe-8fb2-4950-e971-04693d89c4f6"
      },
      "source": [
        "example=\"Silence is golden. Duct tape is silver.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silence is golden. Duct tape is silver.\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1zfJI5mi7lf",
        "outputId": "6db2d30e-df61-4822-9555-e9372ec1ae96"
      },
      "source": [
        "example=\"Its okay if you dont like me. Not everyone has good taste.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its okay if you dont like me. Not everyone has good taste.\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhg5WYpFjrih",
        "outputId": "30346ca8-1948-42ae-c83d-5468c876a08c"
      },
      "source": [
        "example=\"Well at least your mom thinks youre pretty .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Well at least your mom thinks youre pretty .\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyNm3TJ8rPFG",
        "outputId": "cad16b5a-297d-4a4f-b013-53408da5b753"
      },
      "source": [
        "example=\"Me pretending to listen should be enough for you.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Me pretending to listen should be enough for you.\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl1W3sgarmI7",
        "outputId": "2087da64-73b3-4599-fd66-d48fbdb1e216"
      },
      "source": [
        "example=\"Marriage. Because your crappy day doesnt have to end at work.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Marriage. Because your crappy day doesnt have to end at work.\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX4biIhDru-F",
        "outputId": "ddf857e3-bd00-4a50-d559-b91064585a32"
      },
      "source": [
        "example=\"I am so happy to be \n",
        "working with you guys.\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(loaded_model,sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am so happy to be working with you guys.\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}